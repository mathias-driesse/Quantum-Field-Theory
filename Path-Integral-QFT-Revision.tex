%!TEX program = lualatex
\documentclass{article}
\usepackage{physics, amsmath, amsfonts, empheq, mathtools, booktabs, hyperref, simpler-wick, tikz-feynman, slashed, parskip}
\usepackage[style=nature, autocite = inline]{biblatex}
\usepackage[margin=1in]{geometry}

\numberwithin{equation}{section}

\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
\newcommand{\normord}[1]{:\mathrel{#1}:}

\title{Path Integral Quantum Field Theory}
\author{Mathias Driesse}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Gaussian Integrals}

The general Gaussian integral, for a complex, symmetric $n\times n$ matrix $A$ such that $\Re A \geq 0$ and the eigenvalues $a_i$ of $A$ are nonzero, is given by 

\begin{empheq}[box=\widefbox]{align}
    Z_A(b) = \int d^nx \exp\left(-\frac{1}{2} \sum_{i,j = 1}^n x_i A_{ij}x_j + \sum_{i=1}^n b_i x_i\right) = (2\pi)^{n/2} (\det A)^{-1/2} \exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i A_{ij}^{-1}b_j \right).
\end{empheq}

Let $\mu$ be a measure in $\mathbb{R}^n$; we define the expectation value
\begin{equation}
\begin{aligned}
    \ev{F}_\mu &= \int d\mu(x)F(x) \\
    &= \int d^nx\, \Omega(x)F(x).
\end{aligned}
\end{equation}

The measure is normalized so that 
\begin{equation}
    \int d\mu(x) = 1.
\end{equation}

We define the generating function 
\begin{equation}
    Z_\mu(b) = \ev{e^{(b,x)}}_\mu = \int d\mu(x) \exp\left(\sum_{i=1}^n b_i x_i\right),
\end{equation}

which is a function of the $n$-dimensional vector $b$ and the measure $\mu$. The integrand can be expanded
\begin{equation}
    \exp\left(\sum_{i=1}^n b_i x_i\right) = \sum_{\ell=0}^\infty \frac{1}{\ell!} \sum_{i_1 \dots i_\ell = 1}^n b_{i_1} \dots b_{i_\ell} x_{i_1} \dots x_{i_\ell}.
\end{equation}
Therefore, substituting the definition of the correlator
\begin{equation}
    \ev{x_{i_1} \dots x_{i_\ell}}_\mu = \int d\mu(x) x_{i_1} \dots x_{i_\ell}
\end{equation}
we obtain 
\begin{equation}
    Z_\mu(b) = \sum_{\ell=0}^\infty \frac{1}{\ell!} \sum_{i_1 \dots i_\ell = 1}^n b_{i_1} \dots b_{i_\ell} \ev{x_{i_1} \dots x_{i_\ell}}_\mu.
\end{equation}
Furthermore, it is useful to notice that
\begin{equation}
    \pdv{b_k} Z_\mu(b) = \int d\mu(x)x_k \exp\left(\sum_{i=1}^n b_i x_i\right),
\end{equation}
which allows the correlaters to be written as
\begin{equation}
    \ev{x_{i_1} \dots x_{i_\ell}}_\mu = \pdv{b_{i_1}} \dots \pdv{b_{i_\ell}} Z_\mu(b) \eval_{b=0}.
\end{equation}

Let us consider the Gaussian measure
\begin{equation} \label{eq:gaussian_measure}
    d\mu_0(x) = d^nx\, \Omega_0(x) = d^nx \, \mathcal{N}_0 \exp\left(-\frac{1}{2}\sum_{i,j=0}^n x_i A_{ij}x_j\right),
\end{equation}
where the normalization $\mathcal{N}_0$ is fixed by the normalization of the measure:
\begin{equation}
    \mathcal{N}_0 = (2\pi)^{-n/2} (\det A)^{1/2}.
\end{equation}
The generating function in this case can be readily computed using the boxed equation above:
\begin{equation}
    Z(b) = \frac{Z_A(b)}{Z_A(0)} = \exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i A_{ij}^{-1} b_j\right).
\end{equation}
In the future, we will drop any subscript $A$ when referring to a Gaussian measure for simplicity. And therefore, defining $\Delta_{ij} = A_{ij}^{-1}$, 
\begin{empheq}[box=\widefbox]{align} \label{eq:correlator}
    \ev{x_{i_1}\dots x_{i_\ell} }_0 = \pdv{b_{i_1}} \dots \pdv{b_{i_\ell}} \eval{\exp\left(\frac{1}{2}\sum_{i,j=1}^n b_i \Delta_{ij} b_j\right)}_{b=0}.
\end{empheq}

\subsection{Wick's Theorem}

Let us start with a couple explicit examples, which we will compute in full detail in order to get familiar with the algebraic manipulations.

\textbf{One-point function}: Let $k$ be an integer between 1 and $n$, we have 
\begin{equation}
\begin{aligned}
    \ev{x_k}_0 &= \pdv{b_k} \eval{\exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i \Delta_{ij} b_j \right)}_{b=0} \\
    &= \left(\frac{1}{2}\sum_{j=1}^n \Delta_{kj}b_j + \frac{1}{2}\sum_{i=1}^n b_i \Delta_{ik} \right)\eval{\exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i \Delta_{ij} b_j \right)}_{b=0} \\
    &= \left(\sum_{j=1}^n \Delta_{kj}b_j\right)\eval{\exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i \Delta_{ij} b_j \right)}_{b=0} \\
    &= 0,
\end{aligned}
\end{equation}
where the last equality comes from the fact that the expression is linear in $b$, and we need to set $b=0$.

\textbf{Two-point function}: We now consider a pair of indices $k$, $l$, and compute
\begin{equation}
\begin{aligned}
    \ev{x_k x_l}_0 &= \pdv{b_l} \pdv{b_k} \eval{\exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i \Delta_{ij} b_j \right)}_{b=0} \\
    &= \left[\Delta_{kl} + \left(\sum_{j=1}^n \Delta_{kj} b_j \right) \left(\sum_{m=1}^n \Delta_{lm} b_m \right)\right] \eval{\exp\left(\frac{1}{2}\sum_{i,j = 1}^n b_i \Delta_{ij} b_j \right)}_{b=0} \\
    &= \Delta_{kl}
\end{aligned}
\end{equation}

Thus, the generating function $Z(b)$ provides a systematic way to compute all correlators for a multi-dimensional Gaussian distribution. Having understood the general rule for such a process, we can generate a recipe to compute $\ev{x_{i_1} \dots x_{i_\ell}}_0$, known as \textit{Wick's Theorem}:
\begin{itemize}
    \item Write down each $x_{i_1} \dots x_{i_\ell}$ and organize them pairwise $(i_p, i_q)$. Note that if $\ell$ must be even for the correlator to be non-zero.
    \item There are $(\ell - 1)\times(\ell-3) \times \dots \times 3 \times 1$ ways of doing this. Sum over all of these possible pairings.
    \item To each pair $(i_p, i_q)$ associate a factor $\Delta_{i_p i_q}$.
\end{itemize}

Let us revisit our result for the \textbf{two-point function}: for $\ev{x_{i_1} x_{i_2}}_0$, there is only one possible pairing $(i_1, i_2)$. Therefore
\begin{equation}
    \ev{x_{i_1} x_{i_2}}_0 = \Delta_{i_1 i_2}.
\end{equation}

\textbf{Four-point function}: For $\ev{x_{i_1} x_{i_2} x_{i_3} x_{i_4}}_0$, there are three different pairings
\begin{equation}
    P=\left\{\left\{\left(i_1, i_2\right),\left(i_3, i_4\right)\right\},\left\{\left(i_1, i_3\right),\left(i_2, i_4\right)\right\},\left\{\left(i_1, i_4\right),\left(i_2, i_3\right)\right\}\right\}
\end{equation}

Wick's theorem then yields 
\begin{equation}
    \ev{x_{i_1} x_{i_2} x_{i_3} x_{i_4}}_0=\Delta_{i_1 i_2} \Delta_{i_3 i_4}+\Delta_{i_1 i_3} \Delta_{i_2 i_4}+\Delta_{i_1 i_4} \Delta_{i_2 i_3}.
\end{equation}

We can also represent these pairings, \textit{Wick contractions}, as should be familiar from canonical quantum field theory:
\begin{equation}
    \ev{x_i x_j}_0 = \Delta_{ij} = \wick{\c x_i \c x_j}
\end{equation}

\subsection{Perturbed Gaussian Measure}

Let us now consider a more complicated measure,
\begin{equation}
    \Omega(x) = \frac{1}{Z(\lambda)}e^{-S(x, \lambda)},
\end{equation}
where the normalization is given as usual by 
\begin{equation}
    Z(\lambda) = \int d^nx e^{-S(x,\lambda)}
\end{equation}
and
\begin{equation}
\begin{aligned}
    S(x, \lambda) &= \frac{1}{2} \sum_{i, j = 1}^n x_i A_{ij}x_j + \lambda V(x) \\
    &= S_0(x) + \lambda V(x).
\end{aligned}
\end{equation}
We call $V(\lambda)$ the potential term, foreshadowing the physics we will be doing using the perturbed Gaussian measure. Furthermore
\begin{equation}
\begin{aligned}
    Z(\lambda) &= \sum_{k=0}^\infty \frac{(-\lambda)^k}{k!} \int d^nx \, V^k(x) \exp\left(-\frac{1}{2} \sum_{i,j=1}^n x_i A_{ij} x_j\right) \\
    &= Z(0) \sum_{k=0}^\infty \frac{(-\lambda)^k}{k!} \ev{V^k(x)}_0,
\end{aligned}
\end{equation}
where in the first line we have expanded the exponential term containing $e^V(x)$ and in the second line used
\begin{equation}
    \ev{F(x)}_0 = \frac{1}{Z(0)} \int d^nx \exp\left(-\frac{1}{2} \sum_{i,j=1}^n x_i A_{ij} x_j\right) F(x),
\end{equation}
and $1/Z(0)$ referring to the normalization constant $\mathcal{N}_0$ from Eq. \ref{eq:gaussian_measure}. Recalling Eq. \ref{eq:correlator}, given that $F(x)$ admits a Taylor expansion
\begin{equation}
\begin{aligned}
    F(x) &= \sum_{\ell = 0}^\infty \sum_{i_1 \dots i_\ell = 1}^n F_{i_1 \dots i_\ell} x_{i_1} \dots x_{i_\ell} \\
    &= F_0 + F_1 x_1 + \dots + F_n x_n\\
    &\quad + F_{11} x_1^2 + F_{12} x_1 x_2 + \dots + F_{nn} x_n^2 \\
    &\quad + \dots
\end{aligned}
\end{equation}
where $F_{i_1 \dots i_\ell}$ refer to the constant expansion coefficients, we can define the expectation value of $F$ for a generic measure $\mu$ as 
\begin{equation}
    \ev{F(x)}_\mu = \sum_{\ell = 0}^\infty \sum_{i_1 \dots i_\ell = 1}^n F_{i_1 \dots i_\ell} \ev{x_{i_1} \dots x_{i_\ell}}_\mu;
\end{equation}
for the case of a Gaussian measure we obtain
\begin{equation}
\begin{aligned}
    \ev{F(x)}_0 &= \sum_{\ell = 0}^\infty \sum_{i_1 \dots i_\ell = 1}^n F_{i_1 \dots i_\ell} \pdv{b_{i_1}} \dots \pdv{b_{i_\ell}} \eval{\exp\left(\frac{1}{2}\sum_{i,j=1}^n b_i \Delta_{ij} b_j\right)}_{b=0} \\
    &= F \left(\pdv{b}\right) \eval{\exp\left(\frac{1}{2}\sum_{i,j=1}^n b_i \Delta_{ij} b_j\right)}_{b=0}.
\end{aligned}
\end{equation}
Thus, returning to our potential term,
\begin{equation} \label{eq:z0/zlambda}
\begin{aligned}
    \frac{Z(\lambda)}{Z(0)} &= \ev{e^{-\lambda V(x)}}_0 \\
    &= \exp\left[-\lambda V\left(\pdv{b}\right)\right] \eval{\exp\left(\frac{1}{2}\sum_{i,j=1}^n b_i \Delta_{ij} b_j\right)}_{b=0}.
\end{aligned}
\end{equation}

% TODO: include example for V(x) = 1/4! x^4

\subsection{Perturbed Gaussian Correlators}

The perturbative treatment discussed above can be extended to compute moments of the distribution:
\begin{equation} \label{eq:twopoint_correlator}
    \ev{x_{i_1} \dots x_{i_l}} = \frac{\int d^nx \, e^{-S(x,\lambda)} x_{i_1} \dots x_{i_l}}{\int d^nx\, e^{-S(x,\lambda)}} = \frac{1}{Z(\lambda)} \int d^nx\, e^{-S(x,\lambda)} x_{i_1} \dots x_{i_l}
\end{equation}
which is often referred to as an $\ell$-point correlator/function. Let us start our discussion with a simple example. 
\textbf{Two-point function}: we need to evaluate
\begin{equation}
\begin{aligned} \label{eq:two_point_function}
    \int d^nx \, e^{-S(x, \lambda)} x_{i_1} x_{i_2} &= \int d^nx \, e^{-S_0(x, \lambda)} \left[\sum_{k=0}^n \frac{(-\lambda)^k}{k!} \lambda^k V^k(x)\right] x_{i_1} x_{i_2} \\
    &= Z(0) \sum_{k=0}^n \frac{(-\lambda)^k}{k!} \ev{V^k(x) x_{i_1} x_{i_2}},
\end{aligned}
\end{equation}
where in the second line we have expressed the initial correlator in terms of correlators computed in the Gaussian theory, denoted by $\ev{\dots}_0$. The Gaussian correlators can be computed using Wick's theorem as before. We shall consider again a quartic potential
\begin{equation}
    V(x) = \frac{1}{4!} \sum_{i=1}^n x_i^4,
\end{equation}
and compute all the terms in Eq. \ref{eq:two_point_function} order by order in $\lambda$ up to order $\lambda^2$.
\begin{itemize}
    \item $\mathcal{O}(\lambda^0)$: For $k=0$ we simply get the two-point Gaussion correlator
    \begin{equation}
        \ev{x_{i_1}x_{i_2}} = \Delta_{i_1 i_2}.
    \end{equation}
    \item $\mathcal{O}(\lambda^1)$: At first order in $\lambda$ we have one insertion of $V$:
    \begin{equation}
        \ev{V(x)x_{i_1} x_{i_2}}_0 = \frac{1}{4!} \sum_{i = 1}^n \ev{x_i^4 x_{i_1} x_{i_2}}_0.
    \end{equation}
    This Gaussian expectation value involving six factors of $x$ can be evaluated using Wick's theorem. There are two types of contractions.
    \begin{enumerate}
        \item $x_1$ is contracted with $x_2$, and the four $x_i$ are contracted amongst themselves:
        \begin{equation}
            \wick{\c x_{i_1} \c x_{i_2}}(\wick{\c1 x_i \c1 x_i \c1 x_i \c1 x_i + \c1 x_i \c2 x_i \c1 x_i \c2 x_i + \c1 x_i \c2 x_i \c2 x_i \c1 x_i}) = \Delta_{i_1 i_2} \ev{x_i^4}_0
        \end{equation}
        \item $x_1$ and $x_2$ are contracted with some of the $x_i$; there are 12 such contractions:
        \begin{equation}
            \wick{\c1 x_{i_1} \c2 x_{i_2} \c1 x_i \c2 x_i x_i x_i} + \dots = \Delta_{i i_1} \Delta_{i i_2} \Delta_{ii} \times 4 \times 3.
        \end{equation}
        Collecting all the terms yields
        \begin{equation}
            \frac{1}{4!} \sum_{i = 1}^n \ev{x_i^4 x_{i_1} x_{i_2}}_0 = \Delta_{i_1 i_2} \frac{1}{4!} \sum_{i = 1}^n \ev{x_i^4}_0 + \frac{1}{4!} \times 4 \times 3 \sum_{i=1}^n \Delta_{i i_1} \Delta_{i i_2} \Delta_{ii}.
        \end{equation}
    \end{enumerate}
    \item $\mathcal{O}(\lambda^2)$: At this order we need to evaluate
    \begin{equation}
        \frac{1}{2!}\ev{V(x)^2 x_{i_1} x_{i_2}}_0 = \frac{1}{2!} \frac{1}{(4!)^2} \sum_{i,j=1}^n \ev{x_i^4 x_j^4 x_{i_1} x_{i_2}}_0.
    \end{equation}
    There are five different types of contractions, each of them coming with a given multiplicity. We encourage the interested reader to compute those contributions, and check carefullly that the correct multiplicities are recovered. Collecting all contributions yields
    \begin{equation} \label{eq:full_twopoint}
    \begin{aligned}
        \int d^nx e^{-S(x, \lambda)} x_{i_1} x_{i_2} = Z(0) &\Biggl[ \Delta_{i_1 i_2} - \lambda \left(\Delta_{i_1 i_2} \frac{1}{4!} \sum_{i=1}^n \ev{x_i^4}_0 + \frac{1}{2} \sum_{i=1}^n \Delta_{ii_1} \Delta_{ii_2} \Delta_{ii}\right) \\
        &\quad + \lambda^2\Biggl( \frac{1}{2!}\Delta_{i_1 i_2} \frac{1}{(4!)^2} \sum_{i,j=1}^n \ev{x_i^4 x_j^4}_0 + \frac{1}{2!}\sum_{i=1}^n \Delta_{ii_1} \Delta_{ii_2} \Delta_{ii} \frac{1}{4!}\sum_{j=0}^n \ev{x_j^4}_0 \\
        &\quad + \frac{1}{4} \sum_{i,j=1}^n \Delta_{ii_1} \Delta_{ii_2} \Delta_{ij}^2 \Delta_{jj} + \frac{1}{6} \sum_{i,j=1}^n \Delta_{ii_1} \Delta_{ji_2} \Delta_{ij}^3 \\
        &\quad + \frac{1}{4} \sum_{i,j=1}^n \Delta_{ii_1} \Delta_{ji_2} \Delta_{ij} \Delta_{ii } \Delta_{jj} \Biggr)\Biggr].
    \end{aligned}
    \end{equation}
    A term that factorises as the product of a subdiagram with external lines and a subdiagram that is made of loops only is called a \textit{vacuum contribution}. For instance, $\Delta_{i_1 i_2} \frac{1}{4!} \sum_{i=1}^n \ev{x_i^4}_0$ is a vacuum contribution because $\ev{x_i^4}_0$ is one. 

    Finally, we need to divide this expression by $Z(\lambda)$ in order to obtain the two-point correlator as defined in Eq. \ref{eq:twopoint_correlator}. As a result, we obtain a factor $Z(0)/Z(\lambda)$ multiplying the expression inside the square bracket in Eq. \ref{eq:full_twopoint}. The ratio $Z(0)/Z(\lambda)$ may be computed using Eq. \ref{eq:z0/zlambda} and expanding as $1/(1-x) = 1 + x + x^2 + \dots$ and sorting the terms by powers of $\lambda$ to obtain
    \begin{equation}
        Z(0)/Z(\lambda) = 1 + \frac{1}{4!} \sum_{i=1}^n \ev{x_i^4}_0 - \frac{1}{2!} \frac{1}{(4!)^2} \lambda^2 \sum_{i,j=1}^n \ev{x_i^4 x_j^4}_0 + \frac{1}{(4!)^2} \lambda^2 \left(\sum_{i=1}^n \ev{x_i^4}_0 \right)^2 + \mathcal{0}(\lambda^3)
    \end{equation}
    This cancels all vacuum contributions. % TODO: HOW???
\end{itemize}

\subsection{Generating Functions for the Perturbed Gaussian Measure}

We can now generalise the idea of a generating function to the case of a non-Gaussian measure. Introducing 
\begin{equation}
    Z(b, \lambda) = \int d^nx \exp[-S(x,\lambda) + b_i x_i],
\end{equation}
and remembering that we can also write
\begin{equation}
    \ev{e^{b_i x_i}} = Z(b, \lambda)/Z(\lambda),
\end{equation}
the correlators in the perturbed measure are obtained by differentiation
\begin{equation}
    \ev{x_{i_1} \dots x_{i_\ell}} = \eval{\frac{1}{Z(\lambda)} \pdv{b_{i_1}} \dots \pdv{b_{i_\ell}} Z(b, \lambda)}_{b=0}.
\end{equation}

The logarithm of $Z(b, \lambda)$ is usually denoted $W(b, \lambda)$,
\begin{equation}
    Z(b, \lambda) = e^{W(b,\lambda)};
\end{equation}
$W(b, \lambda)$ is the generator of the connected $\ell$-point correlators $W_{i_1 \dots i_\ell}$, i.e. the correlators that can be represented as a single diagram, with $\ell$ open ends:
\begin{equation}
    W_{i_1 \dots i_\ell} = \eval{\pdv{b_{i_1}} \dots \pdv{b_{i_\ell}} W(b, \lambda)}_{b=0}.
\end{equation}
In statistics, the $W_{i_1 \dots i_\ell}$ are called the \textit{cumulants} of the probability distribution $e^{-S(x, \lambda)}$.

\section{Path Integral Quantum Mechanics}

In this section, we will discuss the essentials of the path integral formulation of quantum mechanics, which will allow us to connect Gaussian integrals and the calculation of correlators to observables in quantum field theory. We consider a point particle in one dimension, with position operator $\hat{Q}$ such that
\begin{equation}
    \hat{Q}\ket{q} = q\ket{q}
\end{equation}
with a completeness condition
\begin{equation}
    \int dq \ket{q} \bra{q} = 1.
\end{equation}
The aim of this section is to find an expression for the quantum amplitude $\braket{q't'}{qt} = \mel{q'}{e^{-i\hat{H}(t'-t)}}{q}$ for a Hamiltonian $\hat{H}$.

\subsection{Setting up the Path Integral}

In order to proceed with the calculation, let us define $T=t'-t$ to be the size of the time interval, and $\epsilon=T/n$, where $n$ is an integer. Then
\begin{equation}
\begin{aligned}
    t_0 &= t \\
    t_k &= t_0 = k\epsilon, k=1, \dots, n-1 \\
    t_n &= t + n\epsilon = t' \\
\end{aligned}
\end{equation}
and 
\begin{equation}
\begin{aligned}
    \mel{q'}{e^{-i\hat{H}(t'-t)}}{q} &= \mel{q'}{e^{-i\hat{H}T}}{q} \\
    &= \mel{q'}{\left(e^{-i\hat{H}\epsilon}\right) \dots \left(e^{-i\hat{H}\epsilon}\right)}{q},
\end{aligned}
\end{equation}

where the expression in the second line contains $n$ factors. Inserting the completeness relation $n-1$ times,
\begin{equation}
    \braket{q't'}{qt} \int \prod_{k=1}^{n-1} dq_k \mel{q'}{\left(e^{-i\hat{H}\epsilon}\right)}{q_{n-1}} \mel{q_{n-1}}{\left(e^{-i\hat{H}\epsilon}\right)}{q_{n-2}} \dots \mel{q_1}{\left(e^{-i\hat{H}\epsilon}\right)}{q}.
\end{equation}

For small $\epsilon$ we can expand the exponential to first order and evaluate the matrix elements:
\begin{equation}
\begin{aligned}
    e^{-i\hat{H}\epsilon} &= 1 - i \hat{H} \epsilon + \mathcal{O}(\epsilon^2) \\
    \hat{H} &= \frac{1}{2} \hat{P} + V(\hat{Q}).
\end{aligned}
\end{equation}

From the potential energy we get
\begin{equation}
\begin{aligned}
    \mel{q_k}{V(\hat{Q})}{q_{k-1}} &= V(q_{k-1})\braket{q_k}{q_{k-1}} \\
    &\approx V\left(\frac{q_k + q_{k-1}}{2}\right) \delta(q_k - q_{k-1}) \\
    &= \int \hat{d}p \, V\left(\frac{q_k + q_{k-1}}{2}\right) e^{ip(q_k - q_{k-1})}.
\end{aligned}
\end{equation}

In order to evaluate the contribution of the kinetic term, we introduce eigenstates of the momentum operator $\ket{p}$
\begin{gather}
    \hat{P} \ket{p} = p \ket{p} \\
    \braket{q}{p} = e^{ipq},
\end{gather}
and use the completeness of the states $\ket{p}$:
\begin{equation}
    \mel{q_k}{\hat{P}^2}{q_{k-1}} = \int \hat{d}p\, p^2 e^{ip(q_k - q_{k-1})}.
\end{equation}
Hence, remembering that the exponential of the Hamiltonian has been expanded to linear order,
\begin{equation}
\begin{aligned}
    \mel{q_k}{e^{-i\hat{H}\epsilon}}{q_{k-1}} &= \mel{q_k}{1-i\epsilon \left(\frac{1}{2}\hat{P}^2 + V(\hat{Q})\right)}{q_{k-1}} \\
    &= \int \hat{d}p \, \left[1 - i\epsilon\left(\frac{1}{2}p^2  + V\left(\frac{q_k + q_{k-1}}{2}\right)\right) e^{ip(q_k - q_{k-1})}\right] \\
    &= \int \hat{d}p \, \exp\left[i\epsilon \left(p \frac{q_k - q_{k-1}}{\epsilon} - H(p, \frac{q_k - q_{k-1}}{2})\right)\right] + \mathcal{O}(\epsilon^2).
\end{aligned}
\end{equation}
Therefore
\begin{equation}
    \braket{q't'}{qt} = \lim_{n\rightarrow \infty} \int \prod_{k=1}^{n-1} dq_k \prod_{j=1}^n \hat{d}p_j \, \exp\left\{i\epsilon \sum_{m=1}^n \left[p_m \frac{q_m - q_{m-1}}{\epsilon} - H\left(p_m, \frac{q_m + q_{m-1}}{2}\right)\right]\right\},
\end{equation}
where $q_0 = q$, and $q_n = q'$. The limit above defines the \textit{path integral} evaluation of the quantum amplitude, which we denote 
\begin{empheq}[box=\widefbox]{align} \label{eq:pathintegral}
    \braket{q't'}{qt} = \int \mathcal{D}q \mathcal{D}p \exp\left\{i\int_t^{t'} d\tau \left[p\dot{q} - H(p, q)\right]\right\}.
\end{empheq}

For Hamiltonians where the momentum dependance is \textbf{only quadratic}, the expression above can be simplified by performing the integral over the momenta $p_j$:
\begin{equation}
    \int \hat{dp} \, \exp\left\{i\epsilon \left[p \frac{q_k - q_{k-1}}{\epsilon} - \frac{1}{2}p^2\right]\right\} = (2\pi i \epsilon)^{-1/2} \exp\left\{i\epsilon \frac{1}{2}\left(\frac{q_k - q_{k-1}}{\epsilon}\right)^2\right\}.
\end{equation}
Using this result, we can rewrite the path integral in Eq. \ref{eq:pathintegral} as 
\begin{equation}
    \braket{q't'}{qt} = \lim_{n\rightarrow \infty} (2\pi i \epsilon)^{-n/2}\int \prod_{k=1}^{n-1} dq_k \exp\left\{i\epsilon \sum_{m=1}^n \left[\frac{1}{2}\left(\frac{q_k - q_{k-1}}{\epsilon}\right)^2 - V\left(\frac{q_m + q_{m-1}}{2}\right)\right]\right\},
\end{equation}
and, assuming that the limit exists, we have obtained the definition of the path integral as an integral over the position of the system only:
\begin{empheq}[box=\widefbox]{align}
    \braket{q't'}{qt} = \int \mathcal{D}q \exp\left\{i\int_t^{t'} d\tau\,  L(q, \dot{q})\right\}.
\end{empheq}
    
\subsection{Correlators}

We are now going to work out expressions for the matrix element of the position operator in between the initial and final state considered above. The first example we are going to consider is the matrix element
\begin{equation}
    \mel{q't'}{\hat{Q}(\bar{t})}{qt} = \mel{q'}{e^{-i\hat{H}(t'-t)}\hat{Q} e^{-i\hat{H}(\bar{t}-t)}}{q},
\end{equation}
where we assume $t < \bar{t} < t'$, and we have used
\begin{equation}
    \hat{Q}(t) = e^{i\hat{H}t} \hat{Q} e^{-i\hat{H}t}.
\end{equation}
Proceeding as we did in the previous section, we can write
\begin{equation}
    \mel{q't'}{\hat{Q}(\bar{t})}{qt} = \mel{q'}{\left(e^{-i\hat{H}\epsilon}\right) \dots \left(e^{-i\hat{H}\epsilon}\right) \hat{Q} \left(e^{-i\hat{H}\epsilon}\right) \dots \left(e^{-i\hat{H}\epsilon}\right)}{q}
\end{equation}
where we assumed that $\hat{t} = t_k$, and the first and second ellipses denote respectively $n-k$ and $k$ factors of $\left(e^{-i\hat{H}\epsilon}\right)$. Performing the same manipulations as before we obtain
\begin{equation}
    \mel{q't'}{\hat{Q}(\bar{t})}{qt} = \lim_{n\rightarrow \infty} \int \prod_{k=1}^{n-1} dq_k \prod_{j=1}^n \hat{d}p_j \, q_k \exp\left\{i\epsilon \sum_{m=1}^n \left[p_m \frac{q_m - q_{m-1}}{\epsilon} - H\left(p_m, \frac{q_m + q_{m-1}}{2}\right)\right]\right\}.
\end{equation}
Note the extra factor of $q_k$ in the integrand. We write this limit as 
\begin{equation}
    \mel{q't'}{\hat{Q}(\bar{t})}{qt} = \int_{qq'} \mathcal{D}q\, q(\bar{t}) \exp\left\{i \int_t^{t'} d\tau \mathcal{L}(q, \dot{q})\right\}.    
\end{equation}
The two-point function is 
\begin{equation} \label{eq:twopoint}
    \mel{q't'}{\hat{Q}(\bar{t}_1) \hat{Q}(\bar{t}_2)}{qt},
\end{equation}
where we assume $\bar{t}_1 = t_k$, $\bar{t}_2 = t_\ell$, $t < \bar{t}_2 <  \bar{t}_1 < t'$. Proceeding as above yields
\begin{equation} \label{eq:twopointpath}
    \mel{q't'}{\hat{Q}(\bar{t}_1) \hat{Q}(\bar{t}_2)}{qt} = \int_{qq'}\mathcal{D}q \, q(\bar{t}_1) q(\bar{t}_2) \exp\left\{\int_t^{t'} d\tau \mathcal{L}(q, \dot{q})\right\}.
\end{equation}
There is a subtlety here that is worth noting. The ordering of times in Eq. \ref{eq:twopoint} matters, while it does not in Eq. \ref{eq:twopointpath}. Thus, it is more accurate to say that the path integral we have defined is the result of the \textit{time-ordered product} of the operators
\begin{equation}
\begin{aligned}
    \mel{q't'}{T\left(\hat{Q}(\bar{t}_1) \hat{Q}(\bar{t}_2)\right)}{qt} &= \mel{q't'}{\left(\theta(\bar{t}_1 - \bar{t}_2)\hat{Q}(\bar{t}_1) \hat{Q}(\bar{t}_2)  + \theta(\bar{t}_2 - \bar{t}_1)\hat{Q}(\bar{t}_2) \hat{Q}(\bar{t}_1)\right)}{qt} \\
    &= \int_{qq'}\mathcal{D}q \, q(\bar{t}_1) q(\bar{t}_2) \exp\left\{\int_t^{t'} d\tau \mathcal{L}(q, \dot{q})\right\},
\end{aligned}
\end{equation}
which can be trivially extended to an arbitrary number of insertions of the operator $\hat{Q}$. % TODO: not super happy with how this is presented.

\subsection{Generating functional}

Let us begin with a revision of properties of functional derivatives. A functional $F$ is a mapping from a function $u(x)$ to a number $F[u]$. The functional derivative describes the change of the functional to an infinitesimal variation of the function $u$:
\begin{equation}
    u(x) \mapsto u(x) + \delta u(x).
\end{equation}
We define
\begin{equation}
    \delta F = F[u + \delta u] - F[u] = \int dx \fdv{F}{u(x)} \delta u(x).
\end{equation}
In particular we have the important identity
\begin{equation}
    \fdv{f(x)}f(y) =\delta(x-y).
\end{equation}

Let $f(t)$ and $h(t)$ be two functions. Then we can add so-called source terms to the path integral:
\begin{equation}
    \braket{q't'}{qt}_{f,h} = \int \mathcal{D}q \mathcal{D}p \exp\left\{i\int_t^{t'} d\tau \left[p(\tau)\dot{q}(\tau) - H(p(\tau), q(\tau)) + f(\tau) q(\tau) + h(\tau) p(\tau)\right]\right\}.
\end{equation}
Then we have the useful property that taking functional derivatives with respect to the source fields yields the previously discussed correlators. For example,
\begin{equation}
    \left(\frac{1}{i}\fdv{f(\bar{\tau})}\right) \braket{q't'}{qt}_{f,h} = \int \mathcal{D}q \mathcal{D}p \, q(\bar{\tau})\exp\left\{i\int_t^{t'} d\tau \left[p(\tau)\dot{q}(\tau) - H(p(\tau), q(\tau))\right] + f(\tau) q(\tau) + h(\tau) p(\tau)\right\}.
\end{equation}
The general rule is thus 
\begin{empheq}[box=\widefbox]{align} \label{eq:general_rule}
    \mel{q't'}{T\left(\hat{Q}(t_1) \dots \hat{Q}(t_n)\right)}{qt} = \eval{\left(\frac{1}{i}\fdv{f(t_1)}\right) \dots \left(\frac{1}{i}\fdv{f(t_n)}\right) \braket{q't'}{qt}_{f,h}}_{f,h=0}.
\end{empheq}

% TODO: write out derivation of this relation

\begin{empheq}[box=\widefbox]{align}
    \braket{0}{0}_{f,h} = \int \mathcal{D}p \mathcal{D}q \exp\left\{i \int_{-\infty}^{\infty} d\tau \left[p\dot{q} - (1-i\epsilon) H(p, q) + fq + hp \right]\right\}
\end{empheq}

\section{Path Integral for the Scalar Field}

The Lagrangian for a free real scalar field $\phi(x)$ is given by
\begin{equation}
    \mathcal{L}_0(\phi(x)) = \frac{1}{2}\partial_\mu \phi(x)\partial^\mu \phi(x) - \frac{1}{2}m^2 \phi^2(x).
\end{equation}
Note that $\mathcal{L}_0$ is invariant under Lorentz transformations. From the Euler-Lagrange equation, we derive the equation of motion for the field, the Klein-Gordon equation:
\begin{eqnarray}
    (\partial^2+ m^2) \phi(x) = 0.
\end{eqnarray}
Given the conjugate momentum
\begin{equation}
    \Pi(x) = \pdv{\mathcal{L}_0}{(\partial_0 \phi(x))} = \dot{\phi}(x)  
\end{equation}
we obtain the Hamiltonian
\begin{equation}
\begin{aligned}
    \mathcal{H}_0 &= \Pi(x)\dot{\phi(x)} - \mathcal{L}_0(\phi(x)) \\
    &= \frac{1}{2} \Pi^2(x) + \frac{1}{2}\sum_{k=1}^3 (\partial_k \phi(x))^2 + \frac{1}{2}m^2\phi^2(x).
\end{aligned}
\end{equation}
The quadratic Hamiltonian is the generalization of the harmonic oscillator to the case where we have an infinite number of canonical coordinates, indexed by the continuous spatial coordinate $\underline{x}$.


\subsection{Path Integral}

The vacuum-to-vacuum amplitude in the presence of a source field $J(x)$ is the straightforward generalization fo the expression we have derived for the quantum mechanical system:
\begin{equation}
\begin{aligned}
    q(t) &\mapsto \phi(t, \underline{x}) \\
    \hat{Q}(t) &\mapsto \hat{\phi}(t, \underline{x}) \,\text{(operator)} \\
    f(t) &\mapsto J(t, \underline{x})\, \text{(source)}.
\end{aligned}
\end{equation}

By analogy with the QM computation, we can write the expression for the path integral representation of the vacuum amplitude
\begin{equation} \label{eq:vacuum_amplitude}
    Z_0[J] = \braket{0}{0}_J = \int \mathcal{D} \phi \exp\left\{i S_0 + J \cdot \phi\right\},
\end{equation}
where
\begin{equation} \label{eq:scalar_action}
    S_0[\phi] = \int d^Dx\, \mathcal{L}_0(\phi(x)), \quad J\cdot \phi = \int d^Dx\, J(x) \phi(x).
\end{equation}
% For a free theory the integral in Eq. \ref{eq:vacuum_amplitude} is a Gaussian integral; this is why we have made sure to investigate their properties so carefully. In order to make the correspondence more explicit, we can write the action as 
% \begin{equation}
% \begin{aligned}
%     S_0[\phi] &= \int d^Dx \, \frac{1}{2}\partial_\mu \phi(x)\partial^\mu \phi(x) - \frac{1}{2}m^2 \phi^2(x) +  \int d^Dx\, J(x) \phi(x)\\
%     &= \int d^Dx\, d^Dx'\, \phi(x) K(x, x') \phi(x') + \int d^Dx\, J(x) \phi(x).
% \end{aligned}
% \end{equation} 
% % TODO: kernel thing doesn't seem entirely right..?
% Thus the kernel $K(x, x') = - (\partial^2 + m^2) \delta(x - x')$ plays the role of $A_{ij}$ and $J(x)$ the role of $b_i$.

In momentum space, the kernel in the action is diagonal. Thus, introducing the Fourier transform
\begin{equation}
    \phi(x) = \int \hat{d}^Dp\, e^{-ip \cdot x} \tilde{\phi}(p),
\end{equation}
we can rewrite the kinetic term:
\begin{equation}
\begin{aligned}
    \int d^Dx\, \partial_\mu \phi(x) \partial^\mu \phi(x) &= \int d^Dx \int_{p, p'} (-ip_\mu) e^{-ip\cdot x} \tilde{\phi}(p) (-ip'^\mu) e^{-ip'\cdot x} \tilde{\phi}(p') \\
    &= \int_p p^2 \tilde{\phi}(p) \tilde{\phi}(-p) = \int_p p^2 |\tilde{\phi}(p)|^2
\end{aligned}
\end{equation} 
since we have a factor of $\delta(p + p')$ from the exponential and $\tilde{\phi}(-p) = \tilde{\phi}^*(p)$. Hence the action for the field in momentum space can be written as 
\begin{equation}
    S_0[\phi] + J \cdot \phi = \frac{1}{2} \int_p \left\{\tilde{\phi}(-p)\left[p^2-m^2 + i\epsilon\right] \tilde{\phi}(p) + \tilde{J}(p) \tilde{\phi}(-p) + \tilde{J}(-p) \tilde{\phi}(p)\right\}.
\end{equation}

Note that the contribution from the $\epsilon$ term to the exponential is 
\begin{equation}
    \exp{-\epsilon \int_p \left|\tilde{\phi}(p)\right|^2}
\end{equation}
which is clearly convergent for large values of $|\tilde{\phi}(p)|$. The path integral for the free field is a simple extension of the Gaussian integrals that we have discussed previously. % TODO: re-explain how
The Gaussian integral can be computed by performing a shift of the integration variables
\begin{equation} \label{eq:shift_integration_variables_propagator}
    \tilde{\chi}(p) = \tilde{\phi}(p) + \frac{\tilde{J}(p)}{p^2-m^2+i\epsilon},
\end{equation}
so that 
\begin{equation}
    S_0[\chi] + J \cdot \chi = \frac{1}{2} \int_p \left\{\tilde{\chi}(-p)[p^2 - m^2 + i\epsilon]\tilde{\chi}(p) - \tilde{J}(-p) \frac{1}{p^2 - m^2 + i\epsilon} \tilde{J}(p) \right\}.
\end{equation}
Then up to a normalization factor (i.e. the kinetic term)
\begin{equation} \label{eq:z0}
\begin{aligned}
    Z_0[J] &\propto \exp \frac{i}{2} \int_p \tilde{J}(-p)\frac{-1}{p^2-m^2+i\epsilon}\tilde{J}(p) \\
    &= \exp -\frac{i}{2} \int d^Dx\, d^Dx' \, J(x) \Delta(x, x') J(x') 
\end{aligned}
\end{equation}
where we have introduced the \textit{Feynman propagator} $\Delta$.
\begin{equation}
    \Delta(x, x') = \Delta(x - x') = \int d^{-ip\cdot(x-x')} \frac{1}{p^2-m^2+i\epsilon}.
\end{equation}
% TODO: add kernel bit.

Recalling Eq. \ref{eq:general_rule} and the fact that $Z_0[J] = \braket{0}{0}_J$, we can write correlators as 
\begin{equation}
\begin{aligned}
    \mel{0}{T\left(\phi(x_1) \phi(x_2)\right)}{0}_0 &= \left(\frac{1}{i}\fdv{J(x_1)}\right)\left(\frac{1}{i}\fdv{J(x_2)}\right) \eval{Z_0[J]}_{J=0} \\
    &= i\Delta(x_1 - x_2).
\end{aligned}
\end{equation}

Further correlators are obtained by taking more derivatives. They can be computed in the free theory using Wick's theorem, again following the arguments we used for Gaussian integrals, e.g.:
\begin{equation}
    \mel{0}{T\left(\phi(x_1)\phi(x_2)\phi(x_3)\phi(x_4)\right)}{0}_0 = i^2[\Delta(x_1-x_2) \Delta(x_3-x_4) + \Delta(x_1-x_3)\Delta(x_2-x_4) + \Delta(x_1-x_4)\Delta(x_2-x_3)].
\end{equation}

\subsection{Interacting Theory}
Let us now add an interaction term in the Lagrangian:
\begin{equation}
    \mathcal{L}(\phi(x)) = \mathcal{L}_0(\phi(x)) + V(\phi(x)).
\end{equation}
We are going to consider several examples, e.g. $\phi^3$ theory:
\begin{equation}
    V(\phi(x)) = \frac{1}{3!}g \phi^3(x).
\end{equation}
% TODO: dimensionality of g
Denoting by $S_0[\phi]$ the action of the free theory, we can write the path integral for the interacting theory
\begin{equation}
    Z[J] = \braket{0}{0}_J = \int \mathcal{D}\phi \exp\left\{i\left(S_0[\phi] + \int d^Dx \, V(\phi(x))\right)\right\}
\end{equation}
By performing the same manipulations as Eq. \ref{eq:z0/zlambda}, we obtain
\begin{equation}
    Z[J] = \exp\left\{i \int d^Dx \, V\left(\frac{1}{i}\fdv{J(x)}\right)\right\} Z_0[J],
\end{equation}
and by expanding both exponentials and substituting in Eq. \ref{eq:z0}, we obtain a perturbative expansion to our generating functional:
\begin{equation}
    Z[J] \propto \sum_{V=0}^\infty \frac{1}{V!} \left[\frac{ig}{3!} \int d^Dx \, \left(\frac{1}{i}\fdv{J(x)}\right)^3\right]^V \times \sum_{P=0}^\infty \frac{1}{P!} \left[-\frac{i}{2} \int d^Dy \, d^Dz \, J(y) \Delta(y-z)J(z)\right]^P
\end{equation}

Since each power of $P$ adds two sources and each power of $V$ removes three sources, we are left with $E=2P-3V$ sources. The functional derivatives turn factors of $J$ in the integrand into Dirac delta functions as following:
\begin{equation}
    \fdv{J(x)}\int \dots d^dy \dots J(y)\Delta(y, \dots) \dots = \int \dots \Delta(x, \dots) \dots .
\end{equation}
% TODO: Let us look at the details that enter this contribution.

\section{Scalar Field Correlators}
% TODO: feynman rules!


\subsection{The $S$-matrix}

In order to compute the quantum amplitude for a physical process involving arbitrary numbers of particles in the initial and final state, we need to compute the overlap of a state prepared in the distant past (the so-called \textit{in} state), with the resulting final state in the distant future (the so-called \textit{out} state). If we want to describe a $2 \rightarrow n$ process --- like a $pp$ collision at the LHC --- we need to compute 
\begin{equation}
    \braket{p_1, \dots , p_n; \text{out}}{k_1, k_2; \text{in}}.
\end{equation}

The $S$-matrix allows us to express this scalar product between in- and out-states in terms of the states defined at any common reference time :
\begin{equation}
    \braket{p_1, \dots , p_n; \text{out}}{k_1, k_2; \text{in}} = \mel{p_1, \dots , p_n}{S}{k_1, k_2}.
\end{equation}

It is usual to separate the $S$-matrix into the identity operator, corresponding to the particles not interacting, plus a non-trivial \textit{transition matrix} which is usually denoted $T$:
\begin{equation}
    S = 1 + iT.
\end{equation}




\subsection{Field correlators}\label{sec:field_correlators}
As discussed in the previous lecture, the field correlators are obtained from the partition function by taking functional derivatives:

\begin{equation}
\begin{aligned}
    G^{(n)}(x_1, \dots , x_n) &= \ev{T\left(\phi(x_1) \dots \phi(x_n)\right)}{0} \\
    &= \eval{\left(\frac{1}{i}\fdv{J(x_1)}\right) \dots \left(\frac{1}{i}\fdv{J(x_n)}\right) Z[J]}_{J=0}.
\end{aligned}
\end{equation}

The perturbative definition of the path integral has led to an expansion where we can classify the terms according to the number of currents that appea, which we denoted by $E$ above. Clearly, the only terms that contribute to an $n$-point function are the ones with $E=n$ \footnote{If there are less than $n$ sources, then at least one of the functional derivatives will have nothing to act on, yielding zero. If there are more than $n$ sources, then it will be set to zero when we evaluate the correlator, also yielding zero for the correlator.}. Since we can express $E$ in terms of $P$ and $V$, the calculation of correlators can be expressed as a perturbative expansion in terms of $V$, and therefore in powers of coupling:
\begin{equation}
    G^{(n)}(x_1, \dots, x_n) = \sum_V g^V G^{(n, V)}(x_1, \dots , x_n).
\end{equation}

As we will see in future sections, the \textit{LSZ reduction formula} provides a way to connect correlators in momentum space with $S$-matrix elements. This is intimately related to the structure of divergences which we can explore through \textit{polology}. We shall now explore the calculation of two-point position space correlators and the resulting momentum-space expressions.

% TODO: put in physical states such that it makes sense in the context of LSZ

\subsection{Polology}

In this section, we shall learn some features about the analytic structure of field correlators and discuss their relevance in order to extract physical information from the correlators. These are general properties of correlators and do not rely on perturbation theory.

We begin by writing out an $n$-point correlator in momentum space:
\begin{equation}
    \tilde{G}^{(n)} (p_1, \dots, p_n) = \int d^Dx_1 \dots d^Dx_n \, e^{ip_1\cdot x_1} \dots e^{ip_n \dots x_n} \ev{T\left\{\phi(x_1) \dots \phi(x_n)\right\}}.
\end{equation}
As the integral spans $n$ time dimensions, we need to be careful regarding the ordering of the fields and the $T$-ordered product.

Let us focus on the contribution coming from the sector where the values $x_1^0, \dots, x_r^0$ are all larger than the values of $x_{r+1}^0, \dots , x_n^0$ for some value of $r$ between $1$ and $n-1$. We can write this condition as $\min\{x_1^0 \dots x_r^0\} > \max\{x_{r+1}^0 \dots x_n^0\}$. The contribution can then be written as 
\begin{equation}
\begin{aligned}
    \tilde{G}(p_1, \dots, p_n) \sim &\int d^Dx_1 \dots d^Dx_n \, e^{ip_1\cdot x_1} \dots e^{ip_n \cdot x_n} \\
    &\times \theta(\min\{x_1^0 \dots x_r^0\} - \max\{x_{r+1}^0 \dots x_n^0\}) \\
    &\times \ev{T\left\{\phi(x_1) \dots \phi(x_r)\right\} T \left\{\phi(x_{r+1}) \dots \phi(x_n)\right\}}{0}.
\end{aligned}
\end{equation}
We can insert a complete set of one-particle states between the two $T$-ordered products:
\begin{equation}
\begin{aligned}
    \ev{T\left\{\phi(x_1) \dots \phi(x_r)\right\} T \left\{\phi(x_{r+1}) \dots \phi(x_n)\right\}}{0} = \sum_\sigma \int d\Omega_p \, \mel{0}{T\left\{\phi(x_1) \dots \phi(x_r)\right\} }{\vb{p}, \sigma} \mel{\vb{p}, \sigma}{T \left\{\phi(x_{r+1}) \dots \phi(x_n)\right\}}{0}
\end{aligned}
\end{equation}
Let us evaluate this by doing some rewriting. Suppose that $f(z)$ is a function of a real number $z$, and $p = -i \pdv{z}$ is the familiar quantum mechanical momentum operator. Then
\begin{equation}
    \exp[ipa] f(z) = \exp\left[a \pdv{z}\right] f(z) = \sum_{n=0}^\infty \frac{1}{n!} a^n \pdv[n]{z} f(z) = f(z+a).
\end{equation}
Thus we can see that $\exp[ipa]$ is the generator of translations. This works in an arbitrary number of directions. However, in the case of operators, we act once on the left normally and once on the right with the inverse. Thus for an operator $F(z)$,
\begin{equation}
    \exp[ip\cdot a] F(z) \exp[-ip\cdot a] = F(z+a).
\end{equation}
By defining new integration variables,
\begin{equation}
    x_i = x_1 + y_i, \quad \text{for } i=2, \dots, r,
\end{equation}
we can apply our knowledge of the momentum operator $P$ as a generator of translations to write
\begin{equation}
\begin{aligned}
    \phi\left(x_1\right) \ldots \phi\left(x_r\right) & =\phi\left(x_1\right) \ldots \phi\left(x_1+y_i\right) \ldots \phi\left(x_1+y_r\right) \\
    & =e^{i P \cdot x_1} \phi(0) e^{-i P \cdot x_1} \ldots e^{i P \cdot x_1} \phi\left(y_i\right) e^{-i P \cdot x_1} \ldots e^{i P \cdot x_1} \phi\left(y_r\right) e^{-i P \cdot x_1} \\
    &= e^{i P \cdot x_1} \phi(0) \dots \phi(y_r) e^{-i P \cdot x_1}.
\end{aligned}
\end{equation}
Since $e^{-iP \cdot x_1}\ket{0} = \ket{0}$ and $e^{-iP \cdot x_1}\ket{p, \sigma} = e^{-ip \cdot x_1}\ket{p, \sigma}$,
\begin{equation} \label{eq:x_to_y_mel}
    \mel{0}{T\left\{\phi(x_1) \dots \phi(x_r)\right\}}{\vb{p}, \sigma} = e^{-ip \cdot x_1} \mel{0}{T\left\{\phi(0) \dots \phi(y_r)\right\}}{\vb{p}, \sigma}.
\end{equation}
The exact same procedure can be undergone for the other $T$-ordered product.The argument of the Heaviside theta function can be rewritten as 
\begin{equation}
    \min\left\{x_1^0 \dots x_r^0\right\} - \max\left\{x_{r+1}^0 \dots x_n^0 \right\} = x_1^0 - x_{r+1} + \min\left\{0 \dots y_r^0\right\} - \max\left\{0 \dots y_n^0\right\}.
\end{equation}

Using the integral representation of the Heaviside theta function,
\begin{equation}
    \theta(\tau) = - \frac{1}{2\pi i}\int_{-\infty}^\infty d\omega \frac{e^{-i\omega\tau}}{\omega + i\epsilon},
\end{equation}
yields
\begin{equation}
\begin{aligned}
    \tilde{G}(p_1, \dots, p_n) \sim &\int d^Dx_1 d^Dy_2 \dots d^Dy_r d^Dx_{r+1} d^Dy_{r+2} \dots d^Dy_n \\
    &\times e^{ip_1\cdot x_1} e^{ip_1 \cdot (x_1 + y_2)} \dots e^{ip_r \cdot (x_1 + y_r)} e^{ip_{r+1} \cdot x_{r+1}} e^{ip_{r+2} \cdot (x_{r+1} + y_{r+2})} \dots e^{ip_n \cdot (x_{r+1} + y_n)}\\
    &\times -\frac{1}{2\pi i} \int \frac{d\omega}{\omega+i\epsilon} \exp{-i\omega\left[ x_1^0 - x_{r+1} + \min\left\{0 \dots y_r^0\right\} - \max\left\{0 \dots y_n^0\right\}\right]} \\
    &\times \sum_\sigma \int d\Omega_p \, e^{-ip \cdot x_1}\mel{0}{T\left\{\phi(0) \dots \phi(y_r)\right\} }{\vb{p}, \sigma} e^{ip \cdot x_{r+1}}\mel{\vb{p}, \sigma}{T \left\{\phi(0) \dots \phi(y_n)\right\}}{0}.
\end{aligned}
\end{equation}
Performing the integral over $x_1$ and $x_{r+1}$ yields delta functions in terms of the arguments of the exponential: the four-momenta in the second line, the dummy variable $\omega$ in the third line and the extra exponentials due to Eq. \ref{eq:x_to_y_mel} in the fourth line. We can split these delta functions into a product of delta functions of the space and time components, yielding our final result
\begin{equation}
\begin{aligned}
    \tilde{G}(p_1, \dots, p_n) \sim &\int d^Dy_2 \dots d^Dy_r d^Dy_{r+2} \dots d^Dy_n \\
    &\times e^{ip_1 \cdot y_2} \dots e^{ip_r \cdot y_r}  e^{ip_{r+2} \cdot y_{r+2}} \dots e^{ip_n \cdot y_n}\\
    &\times -\frac{1}{2\pi i} \int \frac{d\omega}{\omega+i\epsilon} \exp{-i\omega\left[\min\left\{0 \dots y_r^0\right\} - \max\left\{0 \dots y_n^0\right\}\right]} \\
    &\times \sum_\sigma \int d\Omega_p \,\mel{0}{T\left\{\phi(0) \dots \phi(y_r)\right\} }{\vb{p}, \sigma} \mel{\vb{p}, \sigma}{T \left\{\phi(0) \dots \phi(y_n)\right\}}{0} \\
    &\times \hat{\delta}(\vb{p} - \vb{p}_1 - \dots - \vb{p}_r) \hat{\delta}(E_p + \omega - p_1^0 - \dots - p_r^0) \\
    &\times \hat{\delta}(\vb{p} - \vb{p}_{r+1} - \dots - \vb{p}_n) \hat{\delta}(E_p + \omega - p_{r+1}^0 - \dots - p_n^0).
\end{aligned}
\end{equation}
Performing the Lorentz-invariant phase space integral\footnote{You're going to have to trust me on this one.} % TODO: find out how he did this 
over the spatial components of $p$ and $\omega$ transforms the delta functions into
\begin{equation}
    \hat{\delta}(p_1 + \dots + p_n) \frac{1}{q^0 - E_p + i\epsilon}\frac{1}{2E_p}
\end{equation}
where the factor of $1/2E_p$ comes from the integration measure $d\Omega_p$ and the four-momentum $q$ is defined as 
\begin{equation}
    q = p_1 + \dots + p_r = -p_{r+1} - \dots - p_n.
\end{equation}


To make it more clear that it is about $q$ being on-shell, we can rewrite
\begin{equation}
\begin{aligned}
    \lim_{q^0 \rightarrow E_p} \frac{1}{q^0 - E_p + i\epsilon}\frac{1}{2E_p} &= \lim_{q^0 \rightarrow E_p} \frac{1}{q^0 - E_p + i\epsilon}\frac{1}{E_p + E_p} \\
    &= \lim_{q^0 \rightarrow E_p} \frac{1}{q^0 - E_p}\frac{1}{q^0 + E_p} \\
    &= \lim_{q^0 \rightarrow E_p} \frac{1}{(q^0)^2 - E_p^2} \\
    &= \lim_{q^0 \rightarrow E_p} \frac{1}{(q^0)^2 - \vb{q}^2 - m_{\text{phys}}^2} \\
    &= \lim_{q^0 \rightarrow E_p} \frac{1}{q^2 - m_{\text{phys}}^2 + i\epsilon}.
\end{aligned}
\end{equation}
The important result here is that the correlators in momentum space have a pole singularity \textbf{whenever $q=p_1 + \dots + p_r$ goes on-shell}.
The residue at this pole will be 
\begin{equation}
\begin{aligned}
    \delta(p_1 + \dots + p_n) \frac{i}{q^2 - m_{\text{phys}}^2 + i\epsilon} \sum_\sigma &\int d^Dy_2 \dots d^Dy_r e^{ip_2 \cdot y_2} \dots e^{ip_r \cdot y_r} \mel{0}{T\left\{\phi(0) \dots \phi(y_r)\right\} }{\vb{q}, \sigma} \\
    \times &\int d^Dy_{r+2} \dots d^Dy_n e^{ip_{r+2} \cdot y_{r+2}} \dots e^{ip_n \cdot y_n} \mel{\vb{q}, \sigma}{T \left\{\phi(0) \dots \phi(y_n)\right\}}{0}
\end{aligned}
\end{equation}

\subsection{LSZ reduction}

An important corollary of what we have just covered is obtained by setting $r=1$. In this case, the correlator in momentum space has a pole whenever $p_1$ is on-shell. However, $p_1$ is somewhat arbitrarily chosen --- we could equivalently relabel the momenta and choose a different sector of the integral --- and therefore the correlator in momentum space has a pole whenever the momentum of any of the fields is on-shell. It follows that an $n$-point correlation function as (at least) $n$ poles, each corresponding to one of the momenta $p_i \rightarrow m_{\text{phys}}^2$. In a real scattering event, we want each of the particles involved in the correlator to be on-shell, so somehow we must assign a value to these poles. The most natural choice is of course the residue. 
\begin{equation}
\begin{aligned}
    \braket{p'_1 \dots p'_{m'}; \text{out}}{p_1 \dots p_m; \text{in}} &= \mel{p'_1 \dots p'_{m'}}{S}{p_1 \dots p_m} \\
    &= \lim_{p_j^2, \, p_k^{\prime 2} \rightarrow m_{\text{phys}}^2} \prod_{k=1}^{m'} (p_k^{\prime 2} - m_{\text{phys}}^2 + i\epsilon) \prod_{j=1}^{m} (p_j^2 - m_{\text{phys}}^2 + i\epsilon) \\
    & \quad \times \tilde{G}^{(m+m')} (p_1, \dots, p_m, -p'_1, \dots, -p'_{m'}),
\end{aligned}
\end{equation}  
where $n=m + m'$, and the fields are normalised so that
\begin{equation}
    \mel{\vb{p}}{\phi(0)}{0} = 1.
\end{equation}
% TODO: include proof for simpler version of LSZ and explain what it means. Problem Set 4.4 seems to be same as Srednicki proof.
% TODO: figure out the bit where LSZ is the same as amputating the sources or something like that?

Therefore, we can compute the $S$-matrix elements by adapting the Feynman rules given in Section \ref{sec:field_correlators}:
\begin{itemize}
    \item We associate an outgoing momentum to the external lines that correspond to particles in the final state, giving a relative minus sign compared to the normal Feynman rules when all momenta are taken to be inwards. 
    \item We multiply each external line by a factor of $-i(p^2 - m_{\text{phys}}^2 + i\epsilon)$, this is part of computing the residue. Correlators multiplied by these factors are called \textit{truncated correlators} or \textit{amputated correlators}. % TODO: example for applying this.
\end{itemize}

\subsection{Källén-Lehmann representation}
Let us now come back to the 2-point function, and find a representation that allows us to extract some physical information about the scalar field. We define the full propagator as 
\begin{equation}
    i\Delta_F(x-y) = \ev{T\left\{\phi(x) \phi(y)\right\}}{0},
\end{equation}
and define the field so that 
\begin{equation} \label{eq:conventions}
    \ev{\phi(x)}{0} = 0, \text{ and } \mel{\vb{p}}{\phi(0)}{0} = 1,
\end{equation}
where $\ket{\vb{p}}$ represents the physical one-particle state, and we have dropped the dependence on $\sigma$. As usual the full propagator in momentum space is defined by taking the Fourier transform:
\begin{equation}
    \tilde{\Delta}_F(p) = \int d^Dx e^{ip \cdot (x-y)} \Delta_F(x-y).
\end{equation}
With these conventions, the free theory result for the propagator is 
\begin{equation}
    \tilde{\Delta}(p) = \frac{i}{p^2-m^2+i\epsilon},
\end{equation}
which has a pole at $p^2=m^2$. For the free particle we find a pole in the propagator, at a value which coincides with the parameter in the Lagrangian.

For the interacting theory, we can derive a general expression, which again does not rely on the perturbative definition of the two-point function. Let us first consider the case where $x^0 > y^0$. We can insert a complete set of zero-, one-, and multi-particle states in between:
\begin{equation}
\begin{aligned}
    \ev{T\left\{\phi(x) \phi(y)\right\}}{0} &= \ev{\phi(x) \phi(y)}{0} \\
    &= \ev{\phi(x)}{0} \!\! \ev{\phi(y)}{0} +\\
    &\quad + \int d\Omega_p \mel{0}{\phi(x)}{\vb{p}}\!\!\mel{\vb{p}}{\phi(y)}{0} +\\
    &\quad + \sum_n \int d\Omega_P \mel{0}{\phi(x)}{\vb{P}, n}\!\! \mel{\vb{P}, n}{\phi(y)}{0}.
\end{aligned}
\end{equation}
Using the same trick as in Eq. \ref{eq:x_to_y_mel}, the conventions defined in Eq. \ref{eq:conventions} simplify the expression above to 
\begin{equation}
    \int d\Omega_p e^{-ip \cdot (x-y)} + \sum_n \int d\Omega_P e^{-ip \cdot (x-y)} |\mel{\vb{P}, n}{\phi(0)}{0}|^2.
\end{equation}
Because we are working with a scalar field, the matrix element $\mel{\vb{p}, n}{\phi(0)}{0}$ is invariant under Lorentz transformations, and therefore can only depend on $p$ via the invariant mass $M^2$. We can therefore introduce the \textit{spectral density}
\begin{equation}
    \rho(s) \equiv \sum_n |\mel{\vb{p}, n}{\phi(0)}{0}|^2 \delta(s-M^2),
\end{equation}
and write the two-point correlator as 
\begin{equation}
    \ev{T\left\{\phi(x) \phi(y)\right\}}{0} = \int d\Omega_p e^{-ip \cdot (x-y)} + \int_{4m_{\text{phys}}^2}^\infty ds \rho(s) \int d\Omega_P e^{-iP \cdot (x-y)}.
\end{equation}
We start the integral at $4m_{\text{phys}}^2$ because we must have $M \geq 2m_{\text{phys}}$ for a multiparticle state, so $M^2 \geq 4m_{\text{phys}}^2$.
Similar manipulations for $y^0 > x^0$ yield
\begin{equation}
    \ev{\phi(y) \phi(x)}{0} = \int d\Omega_p e^{-ip \cdot (y-x)} + \int_{4m_{\text{phys}}^2}^\infty ds \rho(s) \int d\Omega_P e^{-iP \cdot (y-x)}.
\end{equation}
Collecting both contributions to the $T$-ordered product and using 
\begin{equation}
    \frac{1}{i} \int \hat{d}^Dp \frac{e^{-ip \cdot (x-y)}}{p^2-\mu^2 + i\epsilon} = \eval{\theta(x^0 - y^0)\int d^\Omega_p e^{-ip \cdot (x-y)} + \theta(y^0 - x^0) \int d^\Omega_p e^{-ip \cdot (y-x)}}_{p^0 = E_{\vb{p}}}
\end{equation}
we finally obtain 
\begin{equation} \label{eq:almost_kallen_lehmann}
    i\ev{T\left\{\phi(y) \phi(x)\right\}}{0} = \int \hat{d}^Dp e^{-ip \cdot (x-y)} \left[\frac{i}{p^2 - m_{\text{phys}} + i\epsilon} + \int_{4m_{\text{phys}}^2}^\infty ds \rho(s) \frac{i}{p^2 - s + i\epsilon}\right].
\end{equation}
Eq. \ref{eq:almost_kallen_lehmann} allows us to read the expression for the full propagator in momentum space, also known as the \textit{Källén-Lehmann representation}:
\begin{empheq}[box=\widefbox]{align} \label{eq:kallen_lehmann}
    \tilde{\Delta}_F(p) = \frac{i}{p^2 - m_{\text{phys}} + i\epsilon} + \int_{4m_{\text{phys}}^2}^\infty ds \rho(s) \frac{i}{p^2 - s + i\epsilon}
\end{empheq}
We see that the two-point correlator of a field $\phi$ that satisfies the conditions in Eq. \ref{eq:conventions} has a pole for $p^2 = m_{\text{phys}}^2$, with a residue exactly equal to one. Note that the field $\phi$ does not need to be the field that appears in the Lagrangian. Knowledge about the multiparticle states of the theory is encodeded in the spectral density part of the Källén-Lehmann representation.

% TODO (optional): optical theorem

\subsection{Ward identities}
The final example of relations between correlators that we are goign to dicuss are so-called \textit{Ward identities}. Ward identities are equalities between field correlators that are obtained as a consequence of symmetries of the system. In classical mechanics, symmetries of the action translate into conserved currents according to Noether's theorem. As we will show in this section, the analogue of current conservation in quantum field theory is precisely the Ward identity. 

In order to derive the identities, let us start by considering a symmetry transformation of the field, i.e. a transformation
\begin{equation} \label{eq:symmetry_transformation}
    \phi(x) \mapsto \phi'(x) = \phi(x) + \epsilon\delta(\phi(x)),
\end{equation}
such that for constant $\epsilon$ the action is unchanged. If we introduce a dependence on the space-time coordinate, $\epsilon(x)$, then the variation of the action can be written 
\begin{equation}
\begin{aligned}
    \delta S &= \int d^Dx \fdv{S}{\phi(x)} \epsilon(x) \delta\phi(x) \\
    &= -\int d^Dx \, \epsilon(x) \partial_\mu j^\mu(x),
\end{aligned}
\end{equation}
where $j^\mu(x)$ is precisely the Noether current that is conserved in the classical theory. % TODO: clarify
In order to derive the Ward identities, we use Eq. \ref{eq:symmetry_transformation} to perform a change of integration variables in the functional integral
\begin{equation} \label{eq:symmetry_transformation_change_variables}
    \int \mathcal{D}\phi \, e^{iS[\phi]} O(\phi) = \int \mathcal{D}\phi' \, e^{iS[\phi']} O(\phi'),
\end{equation}
where $O$ is an arbitrary function of the field $\phi$ and then expand the RHS to first order in $\epsilon$:
\begin{equation} 
    \int \mathcal{D} \phi \, e^{iS[\phi]} O(\phi) = \int \mathcal{D}\phi e^{iS[\phi]} \left(1 + i\delta S[\phi]\right) \left(O(\phi) + \delta O\right).
\end{equation}
We can now substitute the expressions for $\delta S$ and $\delta O$:
\begin{equation}
    \int \mathcal{D}\phi e^{iS[\phi]} \left(1 - i\int d^Dx \, \epsilon(x) \partial_\mu j^\mu(x)\right) \left(O(\phi) + \int d^Dx \, \fdv{O(\phi)}{\phi(x)}\epsilon(x) \delta \phi(x)\right)
\end{equation}
Thus the difference between the RHS and the LHS of Eq. \ref{eq:symmetry_transformation_change_variables}, ignoring terms of $\mathcal{O}(\epsilon^2)$, is 
\begin{equation}
    \int \mathcal{D}\phi \, e^{iS[\phi]} \left\{-i \int d^Dx \, \epsilon(x) \partial_\mu j^\mu(x) O(\phi) + \int d^Dx \, \fdv{O(\phi)}{\phi(x)} \epsilon(x) \delta \phi(x)\right\} = 0.
\end{equation}
Rearranging the terms above allows us to write the identity in a way that makes its physical content more obvious 
\begin{equation} \label{eq:integrated_ward}
    \int d^Dx \, \epsilon(x) \left\{-i \ev{\partial_\mu j^\mu(x) O(\phi)} + \ev{\fdv{O(\phi)}{\phi(x)} \delta\phi(x)}\right\} = 0.
\end{equation}
Eq. \ref{eq:integrated_ward} is sometimes referred to as an \textit{integrated Ward identity}. Since it has to be satisfied for every function $\epsilon(x)$, we can derive the \textit{Ward identity}:
\begin{empheq}[box=\widefbox]{align}\label{eq:ward_identity}
    -i \ev{\partial_\mu j^\mu(x) O(\phi)} + \ev{\fdv{O(\phi)}{\phi(x)} \delta\phi(x)} = 0.
\end{empheq}
There are two important physical results encoded in Eq. \ref{eq:ward_identity}. 
\begin{enumerate}
    \item Symmetry in QFT translates into a relation between correlators. This is true beyond perturbation theory and is used in defining the renormalization conditions in QFT.
    \item Current conservation in QFT is realised at the level of the insertion of $\partial_\mu j^\mu(x)$ in field correlators, up to the terms that come from the variation of $O$. If $O$ is a product of local fields, this variation is localised in space-time, i.e. the contributions are all proportional to Dirac deltas. These terms are called \textit{contact terms}.
\end{enumerate}

Note that in deriving the Ward identity above we have assumed that the integration measure $\mathcal{D}(\phi)$ is invariant, i.e. $\mathcal{D}\phi = D\phi'$. There are examples where the measure is \textbf{not invariant}, which lead to extra terms in the Ward identites. In these cases the Ward identities are called \textit{anomalous}.

\section{Fermion Fields}

\subsection{Fermionic Path Integral}

For the case of fermion fields, we want to define the path integral following the recipe we used for the scalar field. We will treat the fields $\psi$ and $\bar{\psi}$ as Grassmann variables, i.e. 
\begin{equation}
    {\psi_\alpha(x), \psi_\beta(y)} = 0.
\end{equation}
In order to have a consistent implementation of the anticommuting properties of the fermion fields, the functional derivative with repsect to a Grassmann variable must be a Grassmann variable itself. As a consequence 
\begin{equation}
    \frac{\delta^2 F}{\delta \psi_\alpha(x) \delta\psi_\beta(y)} = - \frac{\delta^2 F}{\delta\psi_\beta(y) \psi_\alpha(x)}
\end{equation}
and 
\begin{equation}
    \frac{\delta^2 F}{\delta \psi_\alpha(x) \delta\psi_\alpha(x)} = 0.
\end{equation}
In the definition of the generating functional (recall Eqs. \ref{eq:vacuum_amplitude}, \ref{eq:scalar_action} for the scalar case, $\int d^Dx \, J(x) \phi(x)$ was the source term in the action), we introduce independent sources for $\psi$ and $\bar{\psi}$:
\begin{equation}
    S_0 = \int d^Dx \, \mathcal{L}_0 + \int d^Dx \, \left[\bar{\eta}(x)\psi(y) + \bar{\psi}(y) \eta(y)\right],
\end{equation}
such that
\begin{align}
    \fdv{\eta(y)} \int d^Dx \, \left[\bar{\eta}(x)\psi(y) + \bar{\psi}(y) \eta(y)\right] &= -\bar{\psi}(x) \\
    \fdv{\bar{\eta}(x)} \int d^Dx \, \left[\bar{\eta}(x)\psi(y) + \bar{\psi}(y) \eta(y)\right] &= \psi(x).
\end{align}
Note the difference of ordering between the two terms in brackets.

The action for the free Dirac field is 
\begin{equation}
    S_0[\psi, \bar{\psi}] = \int d^Dx \, \bar{\psi}(x) (i\slashed{\partial} - m)\psi(x).
\end{equation}
Using the rules above for the functional derivative, we can find the classical equation of motion, i.e. Dirac's equation
\begin{equation}
    \fdv{\bar{\psi}(x)} S_0[\psi, \bar{\psi}] = 0 \implies (i\slashed{\partial} - m)\psi(x).
\end{equation}
By analogy with the scalar case, we can write the generating functional for the free theory:
\begin{equation}
\begin{aligned}
    Z_0[\bar{\eta}, \eta] &= \int \mathcal{D} \psi \, \mathcal{D} \psi \,\exp\left[i (S_0[\psi, \bar{\psi}] + \bar{\eta} \cdot \psi + \bar{\psi} \cdot \eta)\right] \\
    &= \exp\left[-\int d^Dx \, d^Dy \, \bar{\eta}(x) S(x-y) \eta(y)\right].
\end{aligned}
\end{equation}
By a similar method to Eq. \ref{eq:shift_integration_variables_propagator}, the Feynman propagator for the Dirac field is
\begin{empheq}[box=\widefbox]{align}
    S(x-y) = \int_p e^{-ip \cdot (x-y)} \frac{i(\slashed{p} + m)}{p^2 - m^2 + i\epsilon}.
\end{empheq}
Note that, just like in the case of the scalar field, the propagator is the inverse of the quadratic term in the action. The propagator is a $4 \times 4$ matrix in spin space, which we can write explicity:
\begin{equation}
    \ev{T\left\{\psi_\alpha(x)\bar{\psi}_\beta(y)\right\}}{0} = S_{\alpha\beta}(x-y) = \int_p e^{-ip \cdot (x-y)} \frac{i\left((\gamma^\mu)_{\alpha\beta}p_\mu + m \delta_{\alpha\beta}\right)}{p^2-m^2+i\epsilon}.
\end{equation}
Because of the linear term $p$ in the propagator the fermionic propagator is not symmetric in its arguments, and will be denoted with an arrow pointing from one end to the other: 
\begin{equation}
    S(x-y) = \feynmandiagram[small, horizontal=a to b]{
        a [particle = $x$] -- [fermion] b [particle = $y$],
    };
\end{equation} % TODO: fix vertical alignment 
Correlators of fermion fields are computed by taking derivatives with respect to the source fields:
\begin{equation}
    \ev{T\left\{\psi_{\alpha_1} \dots \bar{\psi}_{\beta_1}(y_1) \dots \right\}}{0}_0 = \eval{\left(\frac{1}{i}\fdv{\bar{\eta}_{\alpha_1}(x_1)}\right) \dots \left(i \fdv{\eta_{\beta_1}(y_1)}\right) \dots Z_0[\eta, \bar{\eta}]}_{\eta = \bar{\eta} = 0}
\end{equation}% TODO: why factor of i and not 1/i?

In the interacting theory, if the interactions are specified by a potential $V(\psi, \bar{\psi})$, the generating functional is defined as 
\begin{equation}
    Z[\eta, \bar{\eta}] = \exp\left[i \int d^Dx \, V\left(i \fdv{\eta(x)}, \frac{1}{i} \fdv{\bar{\eta}(x)}\right)\right],
\end{equation}
and the normalization is fixed by requiring 
\begin{equation}
    Z[0,0] = 1.
\end{equation}
Thus, for a perturbative expansion to our generating functional, we require a double expansion in the powers of the interaction and in powers of the propagator.

\section{Gauge Fields}

The action for a gauge field $A_\mu(x)$ can be written as 
\begin{equation} \label{eq:gauge_field_action}
    S[A] = \int d^Dx \, \left(-\frac{1}{4}F_{\mu\nu}(x)F^{\mu\nu}(x)\right),
\end{equation}
where in the case of the electromagnetic field, which we will be discussing for the remainder of the section, $F_{\mu\nu}(x) = \partial_\mu A_\nu(x) - \partial_\nu A_\mu(x)$. Computing the variation of the action yields the classical equations of motion, i.e. Maxwell's equations in vacuo:
\begin{equation}
    \partial_\mu F^{\mu\nu}(x) = 0.
\end{equation}
Note that the action only depends on the field strength $F_{\mu\nu}$, and therefore is invariant under \textit{local gauge transformations}
\begin{equation}
    A_\mu(x) \mapsto A_\mu^\Lambda(x) = A_\mu(x) + \partial_\mu \Lambda(x).
\end{equation}
Other symmetries, like translation invariance and invariance under Lorentz transformations are also encoded in Eq. \ref{eq:gauge_field_action}. The action is quadratic in the fields, and can be recast as 
\begin{equation}
    S[A] = \frac{1}{2}\int d^Dx \, A_\mu(x)[\partial^2 g^{\mu\nu} - \partial^\mu \partial^\nu]A_v(x).
\end{equation} % TODO: show proof

It would be tempting at this stage to define the path integral by analogy to the case of the scalar field:
\begin{equation}
    Z[J] = \int \mathcal{D}A \, \exp{i \int d^Dx \left[-\frac{1}{4}F_{\mu\nu}(x)F^{\mu\nu}(x) + J_\mu(x) A^\mu(x)\right]}.
\end{equation}
Unfortunately, the integral above can be performed iff the kernel is invertible. Writing the action in momentum space yields the kernel in its diagonalised form,
\begin{equation}
    S[A] = \int \hat{d}^Dk \tilde{A}_\mu(k)[K^{\mu\nu}(k)]\tilde{A}_\nu(-k),
\end{equation}
where the kernel is given by 
\begin{equation}
    K^{\mu\nu}(k) = -k^2 g^{\mu\nu} + k^\mu k^\nu.
\end{equation}
Substituting any longitudinal component of the gauge field, $\tilde{A}_\mu(k) = k_\mu \tilde{\Lambda}(k)$ yields
\begin{equation}
\begin{aligned}
    S[A] &= \int \hat{d}^Dk \,k_\mu \tilde{\Lambda}(k)[k^\mu k^\nu - k^2 g^{\mu\nu}]k_\nu \tilde{\Lambda}(k) \\
    &= \int \hat{d}^Dk \, \tilde{\Lambda}(k) (k^4 - k^4)\tilde{\Lambda}(k) \\
    &= 0
\end{aligned}
\end{equation}

Thus, the action does not depend at all on the longitudinal components. They are ``projected out'' of the action, leaving a divergent integral over a non-compact domain. This is a direct consequence of the redundancy in the usage of a four-vector to describe photons. There are indeed four degrees of freedom in a real vector field, which is used to represent photons with only \textbf{two} physical, transverse polarizations. Using a four-vector allows an elegant implementation of Lorentz covariance, but the price we pay is that we have unphysical degrees of freedom in the action. The redundancy is at the origin of the gauge symmetry of the action. Going back to position space, it is easy to see that the longitudinal modes are \textit{pure gauge} ones, i.e. $A_\mu(x) = \partial_\mu \Lambda(x)$. The solution to this problem is to identify the redundant degrees of freedom, and factor out the integration over these modes.

\subsection{Faddeev-Popov method}
We would like to develop a method to separate the physical degrees of freedom from the unphysical degrees of freedom in our path integral. For this, we make use of our knowledge of gauge theory. 
A \textit{gauge orbit} is a set of gauge configurations that are related by gauge transformations:
\begin{equation}
    \Omega_A = \{A_\mu^\Lambda(x) \,\forall \,\Lambda(x)\}.
\end{equation}

As discussed above, for a given $A_\mu(x)$, all the field configurations in $\Omega_A$ represent the same physical state, and therefore a single representative should be included in the path integral for each gauge orbit. We can select such a representative by requiring it to be the solution of a \textit{gauge fixing} condition 
\begin{equation}
    G(A_\mu(x)) = 0.
\end{equation}

In order to insert a gauge fixing condition in the path integral, we are going to make use of the following identity:
\begin{align}
    1 &= \int \mathcal{D} G\, \delta(G) = \int \prod_x \left[dG(x)\delta(G(x))\right] \\
    &= \int \mathcal{D} \Lambda \, \delta(G(A_\mu^\Lambda)) \det\left(\fdv{G(A_\mu^\Lambda)}{\Lambda}\right). \label{eq:jacobian}
\end{align}


As an example, the Lorenz gauge corresponds to the choice 
\begin{equation}
    G(A_\mu(x)) = \partial_\mu A^\mu(x);
\end{equation}
and therefore 
\begin{equation}
\begin{aligned}
    G(A_\mu^\Lambda(x)) &= \partial_\mu(A^\mu(x) + \partial^\mu \Lambda(x)) \\
    &= \partial_\mu A^\mu(x) + \partial^2 \Lambda(x).
\end{aligned}
\end{equation}

In order to compute the Jacobian of the change of variables in Eq. \ref{eq:jacobian}, we need to consider that $G(A_\mu^\Lambda(x))$ is a function of $\Lambda$, so that 
\begin{equation}
    \fdv{G(A_\mu^\Lambda(x))}{\Lambda(y)} = \delta(x-y) \partial^2
\end{equation}
In this simple case, we note that the functional derivative does not depend on the gauge field $A_\mu$, and therefore we do not need to work out the determinant in full detail.

We can now use Eq. \ref{eq:jacobian} and rewrite the functional integral for a gauge theory as 
\begin{equation}
\begin{aligned}
    \int \mathcal{D}A\, e^{iS[A]} &= \det\left(\fdv{G(A_\mu^\Lambda)}{\Lambda}\right) \int \mathcal{D}\Lambda \int \mathcal{D} A \, e^{iS[A]} \delta(G(A_\mu^\Lambda)) \\
    & \propto \int \mathcal{D}\Lambda \int \mathcal{D}A^\Lambda e^{iS[A^\Lambda]} \delta(G(A_\mu^\Lambda)).
\end{aligned}
\end{equation}
We can do this because the integration measure as well as the action are invariant under the gauge transformation.
We have therefore achieved our goal, namely to separate the integration over the gauge copies, which is now factored out in front of the path integral. The remaining integration is over the gauge fields but includes the gauge-fixing delta function, which selects one representative for each gauge orbit. This procedure is called the \textit{Faddeev-Popov} method, and turns out to be particularly simple for the $U(1)$ theory, where the Jacobian turns out to be independent of the gauge field, and drops out of the integral. The procedure yields a more interesting result for the case of non-Abelian gauge symmetry. 

In a generalized gauge,
\begin{equation}
    G(A_\mu(x)) = \partial_\mu A^\mu(x) - \omega(x),
\end{equation}
where $\omega$ is a generic function. Using the Faddeev-Popov trick, we can write the path integral as 
\begin{equation}
    \int \mathcal{D}A\, e^{iS[A]} \propto \int \mathcal{D}\Lambda \int \mathcal{D}A\, e^{iS[A]} \delta\left(\partial_\mu A^\mu(x) - \omega(x)\right).
\end{equation}
Since the path integral is independent of $\omega$, we can multiply it by an arbitrary functional of $\omega$, and then perform a path integral over $\omega$; the result can only change by a normalization of $Z[J]$.
\begin{equation}
\begin{aligned}
    \int \mathcal{D}A\, e^{iS[A]} &\propto \int \mathcal{D} \omega \, \exp\left[-i \int d^Dx \frac{\omega^2(x)}{2\xi}\right] \int \mathcal{D}\Lambda \int \mathcal{D}A\, e^{iS[A]} \delta\left(\partial_\mu A^\mu(x) - \omega(x)\right) \\
    &= \int \mathcal{D} \Lambda \int \mathcal{D} A \, e^{iS[A]} \exp\left[-i \int d^Dx \frac{1}{2\xi} (\partial_\mu A^\mu(x))^2\right].
\end{aligned}
\end{equation}
Once again we have factored out the volume of the gauge orbit, but now instead of a gauge fixing delta function in the path integral, we have a non-trivial weight for the longitudinal modes in the exponential. The modified action can be written as:
\begin{equation}
    S[A] - \frac{1}{2\xi} \int d^Dx \left(\partial_\mu A^\mu(x)\right)^2 = \frac{1}{2} \int d^Dx A_\mu(x) \left[\partial^2 g^{\mu\nu} - \left(1 - \frac{1}{\xi}\right)\partial^\mu \partial^\nu\right] A_\nu(x).
\end{equation}
Where the $\xi$-dependent term is a free scalar field, a \textit{Faddeev-Popov ghost}. Since in the Abelian case, it does not couple to anything else, we may simply ignore it. The new kernel in momentum space is 
\begin{equation}
    K_\xi^{\mu\nu}(k) = -k^2 g^{\mu\nu} + \left(1 - \frac{1}{\xi}\right) k^\mu k^\nu,
\end{equation}
and it can be readily checked that the longitudinal modes are no longer zero modes of $K_\xi$, which is now invertible. Its inverse, which we denote $\tilde{D}_F^{\mu\nu}(k)$ is the Feynman propagator for the photon field:
\begin{equation}
    \tilde{D}_F^{\mu\nu}(k) = \frac{-i}{k^2+i\epsilon}\left[g^{\mu\nu} - (1-\xi)\frac{k^\mu k^\nu}{k^2}\right].
\end{equation}
The choices $\xi = 0$ and $\xi = 1$ are called the Landau and Feynman gauge propagators, respectively. The Gaussian integral for the free theory can now be performed 
\begin{equation}
    Z_0[J] = \exp\left[\frac{1}{2}\int \hat{d}^Dk \tilde{J}_\mu(k) \tilde{D}_F^{\mu\nu}(k) \tilde{J}_\nu(-k)\right].
\end{equation}
The propagator in momentum space is obtained by Fourier transforming the expression in momentum space, 
\begin{equation}
\begin{aligned}
    D_f^{\mu\nu}(x-y) &= \int \hat{d}^Dk e^{-ik \cdot (x-y)} \tilde{D}_F^{\mu\nu}(k) \\
    &= \feynmandiagram[small, horizontal=a to b]{
        a [particle = $x$] -- [photon] b [particle = $y$],
    };.
\end{aligned}
\end{equation}

\section{Divergences}

\subsection{A first look at divergences}

In this section we will aim to develop a self-consistent treatment of divergences in quantum field theory. This is a vast topic, which can hardly be addressed exhaustively in the time that we have. Therefore, we will follow the following steps:
\begin{enumerate}
    \item Compute the scalar two-point function beyond the first order in perturbation theory. As we try to perform this calculation we will encounter our first divergent integral.
    \item Discuss the regularization of divergences; i.e. a procedure that allows us to manipulate well-defined mathematical expressions, and to identify the structure of the divergences.
    \item Discuss the renormalization of divergences, i.e. the conditions that are necessary for a quantum field theory to produce finite, unambiguous predictions.
\end{enumerate}

Working in perturbation theory, we compute the two-point function
\begin{equation} \label{eq:scalar_two_point_function}
    \tilde{G}^{(2)}(p, p') = \hat{\delta}(p + p')\frac{1}{i}\tilde{\Delta}_F(p),
\end{equation}
as a Taylor expansion in powers of the coupling constant 
\begin{equation}
    \tilde{G}^{(2)}(p, p') = \sum_k g^k\tilde{G}^{(2,k)}(p, p'). 
\end{equation}
As discussed before, the delta function in Eq. \ref{eq:scalar_two_point_function} ensures momentum conservation. For all pratical purposes, we should remember that it is there, and work in the perturbative expansion of the full propagator 
\begin{equation}
    \tilde{\Delta}_F(p) = \sum_k g^k \tilde{\Delta}_F^{(k)}(p).
\end{equation}
From our previous computations % TODO: which ones?
\begin{equation}
    \frac{1}{i}\tilde{\Delta}_F^{(2)}(p^2) = \frac{1}{i} \tilde{\Delta}(p^2) \left(i \Pi(p^2)\right) \frac{1}{i} \tilde{\Delta}(p^2)
\end{equation}
where 
\begin{equation}
    \tilde{\Delta}(p^2) = \frac{1}{p^2 + m^2 + i\epsilon}
\end{equation}
is the free-field propagator, and 
\begin{equation}
\begin{aligned}
    i\Pi(p^2) &= \frac{1}{2}(ig)^2 \left(\frac{1}{i}\right)^2 \int \hat{d}^D\ell \frac{1}{l^2 - m^2 + i\epsilon} \frac{1}{(l - p)^2 - m^2 + i\epsilon}\\
    &= \frac{1}{2}(ig)^2 \left(\frac{1}{i}\right)^2 \int \hat{d}^D\ell \tilde{\Delta}(l^2) \tilde{\Delta}((l-p)^2)
\end{aligned}
\end{equation}
is the \textit{self-energy}.

Let us evaluate the self-energy using the technique of \textit{Feynman parameters}, using the general formula 
\begin{equation}
\begin{aligned}
    \frac{1}{A_1^{\alpha_1} \dots A_n^{\alpha_n}} = &\frac{\Gamma(\alpha_1 + \dots + \alpha_n)}{\Gamma(\alpha_1) \dots \Gamma(\alpha_n)} \int_0^1 dx_1 \dots \int_0^1 dx_n \, x_1^{\alpha_1 - 1} \dots x_n^{\alpha_n - 1} \times \\
    &\times \delta(1 - x_1 - \dots - x_n) \frac{1}{\left(x_1 A_1 + \dots + x_n A_n\right)^{\alpha_1 + \dots + \alpha_n}}.
\end{aligned}
\end{equation}

Applying it to the integrand above yields 
\begin{equation}
\begin{aligned}
    \frac{1}{l^2 - m^2 + i\epsilon} \frac{1}{(l - p)^2 - m^2 + i\epsilon} &= \frac{\Gamma(1+1)}{\Gamma(1) \Gamma(1)} \int_0^1 dx_1 \int_0^1 dx_2\, \delta(1-x_1-x_2) \frac{1}{(x_1(l^2-m^2+i\epsilon) + x_2((l-p)^2 - m^2 + i\epsilon))^{1+1}} \\
    &= \int_0^1 dx_2 \frac{1}{(l^2 - m^2 - 2xlp + xp^2)^2} \\
    &= \int_0^1 dx \frac{1}{(q^2 - M^2 + i\epsilon)^2},
\end{aligned}
\end{equation}
where $q = l - xp$ and $M^2(x, p) = m^2 - x(1-x)p^2$. Hence, we have 
\begin{equation}
    i\Pi(p^2) = \frac{g^2}{2} \int_0^1 dx \int \hat{d}^Dq \frac{1}{(q^2 - M^2 + i\epsilon)^2}.
\end{equation}

It is useful to introduce Euclidean momenta in order to perform the integration. Because of the location of the poles (below the real axis on the interval $\Re q^0 > 0$, above the real axis on the interval $\Re q^0 < 0$), we can rotate the integration contour clockwise by $\pi/2$ to rune along the purely imaginary axis. This is known as a \textit{Wick rotation}. Introducing 
\begin{equation}
    q^0 = i q_E^0, \quad \vb{q} = \vb{q}_E,
\end{equation}
we can rewrite $(q^2 - M^2)^2 = ((iq^0_E)^2 - \vb{q}_E^2 - M^2)^2 = (q^2 + M^2)^2$:
\begin{equation} \label{eq:pi}
    \Pi(p^2) = \frac{g^2}{2} \int_0^1 dx \int \hat{d}^Dq_E \frac{1}{(q_E^2 + M^2)^2}.
\end{equation}

Note that we have dropped the $i$ in front because of the Wick rotation of the differential. Since there are four powers of $q_E$ in the denominator and $D$ powers of $q_E$ in the numerator, the integral is clearly divergent for $D \geq 4$. In particular, it is quadratically divergent in the UV for the case $D=6$, which is the one we will be interested in. Before developing more sophisticated tools, we can make a simple, but rather deep, observation. If we take the derivative of $\Pi(p^2)$ with respect to $p^2$:
\begin{equation}
\begin{aligned}
    \Pi'(p^2) &= \frac{g^2}{2} \int_0^1 dx \int \hat{d}^Dq_E \frac{-1}{(q_E^2 + M^2)^3} \left(x(x-1)\right) \\
    &= -g^2 \int_0^1 dx\, x(x-1) \int \hat{d}^Dq_E \frac{1}{(q_E^2 +M^2)^3},
\end{aligned}
\end{equation}
which is still divergent, but only for $D\geq 6$. Similarly
\begin{equation}
    \Pi''(p^2) = 3g^2 \int_0^1 dx\, x^2(x-1)^2 \int \hat{d}^Dq_E \frac{1}{(q_E^2 + M^2)^4}
\end{equation}
is divergent only for $D\geq 8$, and in particular is finite for $D=6$. Therefore, the function $\Pi(p^2)$ can be reconstructed by integrating its second derivative twice,
\begin{equation}
    \Pi(p^2) = \Pi(\mu_1^2) + \Pi'(\mu_2^2)(p^2 - \mu_1^2) + \int_{\mu_1^2}^{p^2} ds' \int_{\mu_2^2}^{s'} ds\, \Pi''(s).
\end{equation}
Thus, $\Pi(p^2)$ in $D=6$ is well-defined for all values of $p^2$, provided we fix the values $\Pi(\mu_1^2)$ and $\Pi'(\mu_2^2)$, i.e. the values of the function and its derivative at two \textit{arbitrary} values of the scale.

\subsection{Regularization}

In order to make progress in our understanding of these divergences, we first need to regulate the theory, i.e. we need to choose a prescription that makes the loop integrals mathematically well-defined. This is clearly a necessary condition in order to be able to manipulate these expressions, and eventually define a predictive theory that yields finite results for physical quantities. 

There are serveral ways of regularizing a theory, here we list some of the most common procedures, some of which we will explore in tutorials:
\begin{enumerate}
    \item Sharp cutoff in Euclidean momenta, $q_E^2 \leq \Lambda^2$.
    \item Pauli-villars regulator. The propagators are modified in order to have a less divergent behaviour at large values of the momenta:
    \begin{equation}
        \frac{1}{p^2 - m^2 + i\epsilon} \mapsto \frac{1}{p^2 - m^2 + i\epsilon} - \frac{1}{p^2 - M^2 + i\epsilon}.
    \end{equation}
    \item Schwinger-time regularization.
    \item Work in generic dimension $D$, and define the divergent integrals by analytic continuation.
\end{enumerate}

\subsection{Dimensional Regularization}

In dimensional regularization, loop integrals are computed in a generic dimension $D$, where the integration is actually convergent, and then defined for arbitrary values of $D$ by analytical continuation. Let us look at the integral that we encountered above for the two-point function. After Wick rotation, we are interested in 
\begin{equation}
    I_D = \int \hat{d}^Dq_E \frac{1}{(q_E^2 + m^2)^2},
\end{equation}
which is easily switched to spherical coordinates:
\begin{equation} \label{eq:I_D}
\begin{aligned}
    I_D &= \int \hat{d}\Omega_D \frac{1}{2} \int_0^\infty dq_E^2 (q_E^2)^{D/2-1} \frac{1}{(q_E^2 + M^2)^2} \\
    &= \frac{1}{(2\pi)^D}
    &= \frac{1}{(4\pi)^{D/2}} \frac{\Gamma(2-D/2)}{\Gamma(2)} \left(\frac{1}{M^2}\right)^{2-D/2}.
\end{aligned}
\end{equation} % TODO: fill in and explanation

Eq. \ref{eq:I_D} provides an expression for $I_D$ which can be extended by analytical continuation to arbitrary values of $D$. It is interesting to note that the divergences that we identified in $D=4$ and $D=6$ appear in the regularized version as poles of the gamma function for negative integer values of its argument. 

\subsection{Structure of divergences}

So far, we have avoided discussing the issue of dimensions and units in detail in quantum field theory. Let us review what we need for the following section. In natural units, we reduce all units to powers of mass by setting $\hbar = c = k_B = 1$ - not just setting their value, but their dimensionality too. The mass dimension is the power of mass for that unit. For example, momentum has mass dimension 1, and lengths have mass dimension $-1$. We denote by $[\alpha]$ the mass dimension for some quantity $\alpha$. Since mass dimension is an exponentiated quantity, we have $[\alpha\beta] = [\alpha] + [\beta]$. 

Consider the $\phi^3$ theory Lagrangian
\begin{equation}
    \mathcal{L} = \frac{1}{2}(\partial_\mu \phi)(\partial^\mu \phi) + \frac{1}{2}m^2 \phi^2 + \frac{1}{3!}g \phi^3.
\end{equation}
We know that the action
\begin{equation}
    S = \int d^Dx \mathcal{L}
\end{equation}
is dimensionless. Furthermore, since $[d^Dx] = -D$ we must have $[\mathcal{L}] = D$. In the first term of the Lagrangian, $[\partial_\mu] = [\partial^\mu] = [1/x] = 1$, so we must have $[\phi] = (D-2)/2$. We must also have that $[g\phi^3] = [\mathcal{L}] = D$, so
\begin{equation}
    [g] = [\mathcal{L}] - [\phi^3] = \frac{6-D}{2}.
\end{equation}
That means that in $D=6$, the coupling is dimensionless. This property is useful for the cleanliness of our perturbation theory, so in the future we will consider $D=6$ as the desired limit. To take this limit, we consider $D=6-2\varepsilon$, in which our gamma functions do not diverge. Then $[\phi] 2-\varepsilon$ and $[g] = \varepsilon$. To preserve dimensionless in the coupling constant, we replace $g$ in the action by $g\tilde{\mu}^\epsilon$, where $\tilde{\mu}$ is an arbitrary scale. This seemingly harmless rescaling has deep consequences: the regularization procedure - in this case changing the number of space-time dimensions - has automatically introduced a new scale in the problem. 

Performing this rescaling in our expression for $\Pi(p^2)$ (Eq. \ref{eq:pi}) and substituting our expression for $I_D$ (Eq. \ref{eq:I_D}) yields
\begin{equation}
    \Pi(p^2) = \frac{g^2}{2} \tilde{\mu}^{2\epsilon} \int_0^1 dx \frac{1}{(4\pi)^{D/2}}
\end{equation}


\end{document}